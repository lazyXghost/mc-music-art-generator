{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### OUTLIER REMOVAL AND AVERAGING ######################\n",
    "# plt.boxplot(y)\n",
    "# plt.show()\n",
    "\n",
    "# skc = 1\n",
    "# att = sorted(sorted([(y[i],i) for i in range(len(y))], reverse=True)[skc:-skc], key=lambda x: x[1])\n",
    "# y_cleaned = [x[0] for x in att]\n",
    "\n",
    "# plt.plot(normalized_tone[:5000])\n",
    "# new_tone = []\n",
    "# sz = 2\n",
    "# avg = 0\n",
    "# for i in range(sz):\n",
    "#     avg += y[i]\n",
    "# avg /= sz\n",
    "# new_tone.append(avg)\n",
    "# for j in range(sz, len(y)):\n",
    "#     avg += y[j]/sz - y[j-sz]/sz\n",
    "#     new_tone.append(avg)\n",
    "#################### OUTLIER REMOVAL AND AVERAGING ######################\n",
    "\n",
    "#################### MIXED SIGNAL ######################\n",
    "# import numpy as np\n",
    "# from matplotlib import pyplot as plt\n",
    "# from scipy.io.wavfile import write\n",
    "\n",
    "# Remember SAMPLE_RATE = 44100 Hz is our playback rate\n",
    "# SAMPLE_RATE = 44100  # Hertz\n",
    "# write(\"mysinewave.wav\", SAMPLE_RATE, normalized_tone)\n",
    "\n",
    "# DURATION = 5  # Seconds\n",
    "\n",
    "# def generate_sine_wave(freq, sample_rate, duration):\n",
    "#     x = np.linspace(0, duration, sample_rate * duration, endpoint=False)\n",
    "#     frequencies = x * freq\n",
    "#     # 2pi because np.sin takes radians\n",
    "#     y = np.sin((2 * np.pi) * frequencies)\n",
    "#     return x, y\n",
    "\n",
    "# _, nice_tone = generate_sine_wave(400, SAMPLE_RATE, DURATION)\n",
    "# _, noise_tone = generate_sine_wave(4000, SAMPLE_RATE, DURATION)\n",
    "# noise_tone = noise_tone * 0.3\n",
    "\n",
    "# mixed_tone = nice_tone + noise_tone\n",
    "# normalized_tone = np.int16((mixed_tone / mixed_tone.max()) * 32767)\n",
    "#################### MIXED SIGNAL ######################\n",
    "\n",
    "\n",
    "#################### FFT ######################\n",
    "# from scipy.fft import fft, fftfreq\n",
    "\n",
    "# # Number of samples in normalized_tone\n",
    "# N = SAMPLE_RATE * DURATION\n",
    "\n",
    "# yf = fft(normalized_tone)\n",
    "# xf = fftfreq(N, 1 / SAMPLE_RATE)\n",
    "\n",
    "# print(xf, yf)\n",
    "\n",
    "# plt.scatter(xf, np.abs(yf))\n",
    "# plt.show()\n",
    "#################### FFT ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import itertools\n",
    "import os\n",
    "import soundfile as sf\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class AudioManipulator:\n",
    "    def __init__(self):\n",
    "        self.chroma_hop_length=12\n",
    "        self.normalizationValue = 32767.00\n",
    "        self.n_mels = 128 * 2\n",
    "\n",
    "    def getAudioInterface(self, audio):\n",
    "        return ipd.Audio(audio)\n",
    "\n",
    "    def splitAudio(self, audio, sr, save_path, start_time, end_time):\n",
    "        audio = audio[int(sr * start_time):int(sr * end_time)]\n",
    "        sf.write(save_path, audio, sr)\n",
    "    \n",
    "    def shiftPitchOfAudio(self, audio, sr, pitch_shift):\n",
    "        audio_with_pitch = librosa.effects.pitch_shift(audio, sr=sr, n_steps=pitch_shift)\n",
    "        return audio_with_pitch\n",
    "\n",
    "    def getStft(self, audio):\n",
    "        stft = librosa.stft(audio)\n",
    "        stft_db = librosa.amplitude_to_db(abs(stft))\n",
    "        return stft, stft_db\n",
    "    \n",
    "    def getMelSpectogram(self, audio, sr):\n",
    "        mel_spec = librosa.feature.melspectrogram(y=audio, sr = sr, n_mels = self.n_mels)\n",
    "        mel_spec_db = librosa.amplitude_to_db(mel_spec) # ref = np.max\n",
    "        return mel_spec, mel_spec_db\n",
    "    \n",
    "    def getChromaGram(self, audio, sr):\n",
    "        chromaGram = librosa.feature.chroma_stft(y=audio, sr=sr, hop_length=self.chroma_hop_length)\n",
    "        return chromaGram\n",
    "    \n",
    "    def compareTwoAudios(self, audio1, audio2, sr):\n",
    "        mel1 = self.getMelSpectogram(audio1, sr)\n",
    "        mel2 = self.getMelSpectogram(audio2, sr)\n",
    "        \n",
    "        similarity = np.dot(mel1.flatten(), mel2.flatten()) / (np.linalg.norm(mel1) * np.linalg.norm(mel2))\n",
    "        return similarity\n",
    "\n",
    "    def drawAudio(self, audio, sr):\n",
    "        plt.figure(figsize=(8.8, 3))\n",
    "        plt.plot([(i+1)/sr for i in range(len(audio))], audio)\n",
    "        plt.title('Raw Audio Example')\n",
    "        plt.show()\n",
    "\n",
    "    def drawAudioSpectrum(self, audio, sr):\n",
    "        X, Xdb= self.getStft(audio)\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    def drawAudioSpectrumNormalized(self, audio, sr):\n",
    "        X, Xdb = self.getStft(audio/audio.max() * self.normalizationValue)\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    def drawMelSpectrogram(self, audio, sr):\n",
    "        S, S_db_mel = self.getMelSpectogram(audio, sr)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 3))\n",
    "        img = librosa.display.specshow(S_db_mel,\n",
    "                                    x_axis='time',\n",
    "                                    y_axis='log',\n",
    "                                    ax=ax)\n",
    "        ax.set_title('Mel Spectogram Example', fontsize=20)\n",
    "        fig.colorbar(img, ax=ax, format=f'%0.2f')\n",
    "        plt.show()\n",
    "\n",
    "    def drawChromaGram(self, audio, sr):\n",
    "        chromagram = self.getChromaGram(audio, sr)\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        librosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', hop_length=self.chroma_hop_length, cmap='coolwarm')\n",
    "\n",
    "class MinecraftAudioMatcher:\n",
    "    def __init__(self, mainAudio, baseSoundsPath):\n",
    "        self.pitch_shifts = [6,12,18]\n",
    "        self.mainAudio = mainAudio\n",
    "        self.baseSoundsPath = baseSoundsPath\n",
    "        self.manipulator = AudioManipulator()\n",
    "        \n",
    "    def getAllBaseSoundsNotes(self):\n",
    "        sounds = []\n",
    "        for sound_file_name in os.listdir(self.baseSoundsPath):\n",
    "            sound, sr = librosa.load(self.baseSoundsPath + sound_file_name)\n",
    "            sounds.append((sound, sr, sound_file_name))\n",
    "\n",
    "        combinations = []\n",
    "        for sound, pitch_shift in itertools.product(sounds, self.pitch_shifts):\n",
    "            shifted_sound = self.manipulator.shiftPitchOfAudio(sound[0], sound[1], pitch_shift)\n",
    "            combinations.append((shifted_sound, sound[1], sound[2], pitch_shift))\n",
    "        return combinations\n",
    "\n",
    "    def findBestNotes(self, maxNotesCount):\n",
    "        all_base_sounds = self.getAllBaseSoundsNotes(self.baseSoundsPath)\n",
    "\n",
    "        best_matches = []\n",
    "        for r in range(1, maxNotesCount + 1):\n",
    "            selected_combinations = itertools.combinations(all_base_sounds, r)\n",
    "            for combination in selected_combinations:\n",
    "                combined_audio = np.sum([audio for audio, _ in combination], axis=0)\n",
    "                similarity = self.manipulator.compareTwoAudios(combined_audio, self.mainAudio)\n",
    "                best_matches.append((similarity, combination))\n",
    "\n",
    "        best_matches.sort(key=lambda x: x[0], reverse=True)\n",
    "        best_matches = best_matches[:maxNotesCount]\n",
    "\n",
    "        return best_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Assuming you have mainAudio and baseSoundsPath ready\n",
    "matcher = MinecraftAudioMatcher(mainAudio, baseSoundsPath)\n",
    "best_notes = matcher.findBestNotes(maxNotesCount=9)\n",
    "for similarity, combination in best_notes:\n",
    "    print(\"Similarity:\", similarity)\n",
    "    print(\"Combination:\", combination)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
